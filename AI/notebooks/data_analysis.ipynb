{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../datasets/data/sample_dataset/'\n",
    "TRAIN_PATH = DATASET_PATH + 'train_sample_videos/'\n",
    "TEST_PATH = DATASET_PATH + 'test_videos/'\n",
    "MODELS_PATH = '../models/'\n",
    "HAAR_CASCADE_PATH = '../models/haar_cascade/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 401\n",
      "Number of test files: 400\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(TRAIN_PATH)\n",
    "training_files = len(train_files)\n",
    "\n",
    "test_files = os.listdir(TEST_PATH)\n",
    "test_files = len(test_files)\n",
    "\n",
    "print(f\"Number of training files: {training_files}\")\n",
    "print(f\"Number of test files: {test_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': defaultdict(<function __main__.<lambda>()>,\n",
       "             {'mp4': 400, 'json': 1}),\n",
       " 'testing': defaultdict(<function __main__.<lambda>()>, {'mp4': 400})}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "fileTypes = {\n",
    "    'training': defaultdict(lambda: 0),\n",
    "    'testing': defaultdict(lambda: 0),\n",
    "}\n",
    "\n",
    "for file in os.listdir(TRAIN_PATH):\n",
    "    extension = file.split('.')[-1]\n",
    "    fileTypes['training'][extension] += 1\n",
    "\n",
    "for file in os.listdir(TEST_PATH):\n",
    "    extension = file.split('.')[-1]\n",
    "    fileTypes['testing'][extension] += 1\n",
    "\n",
    "fileTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "323\n",
      "['aagfhgtpmv.mp4', 'aapnvogymq.mp4', 'abarnvbtwb.mp4', 'abofeumbvv.mp4', 'abqwwspghj.mp4']\n",
      "['vudstovrck.mp4', 'jdubbvfswz.mp4', 'atvmxvwyns.mp4', 'qzimuostzz.mp4', 'kbvibjhfzo.mp4']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "real_train_data = []\n",
    "fake_train_data = []\n",
    "\n",
    "data = json.load(open(TRAIN_PATH + 'metadata.json'))\n",
    "\n",
    "for k, v in data.items():\n",
    "    fake_train_data.append(k)\n",
    "    if v['original'] is not None:\n",
    "        real_train_data.append(v['original'])\n",
    "\n",
    "print(len(fake_train_data))\n",
    "print(len(real_train_data))\n",
    "print(fake_train_data[:5])\n",
    "print(real_train_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_from_video_list(video_path_list, video_folder=TRAIN_PATH):\n",
    "    '''\n",
    "    input: video_path_list - path for video\n",
    "    process:\n",
    "    0. for each video in the video path list\n",
    "        1. perform a video capture from the video\n",
    "        2. read the image\n",
    "        3. display the image\n",
    "    '''\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2,3,figsize=(16,8))\n",
    "    for i, video_file in enumerate(video_path_list):\n",
    "        video_path = os.path.join(video_folder,video_file)\n",
    "        capture_image = cv.VideoCapture(video_path) \n",
    "        ret, frame = capture_image.read()\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        ax[i//3, i%3].imshow(frame)\n",
    "        ax[i//3, i%3].set_title(f\"Video: {video_file}\")\n",
    "        ax[i//3, i%3].axis('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aagfhgtpmv.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>vudstovrck.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aapnvogymq.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>jdubbvfswz.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abarnvbtwb.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abofeumbvv.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>atvmxvwyns.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abqwwspghj.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>qzimuostzz.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label  split        original\n",
       "aagfhgtpmv.mp4  FAKE  train  vudstovrck.mp4\n",
       "aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4\n",
       "abarnvbtwb.mp4  REAL  train            None\n",
       "abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4\n",
       "abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json(TRAIN_PATH + 'metadata.json').T\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "\n",
    "- Split the video into frames\n",
    "- crop the face from each frame\n",
    "- save the face cropped video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object frame_extract at 0x7fca50d6cc80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def frame_extract(path):\n",
    "    vidObj = cv.VideoCapture(path) \n",
    "    success = 1\n",
    "    while success:\n",
    "        success, image = vidObj.read()\n",
    "        if success:\n",
    "            yield image\n",
    "\n",
    "frame_extract(TRAIN_PATH + train_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_number_of_frames(video_path):\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    length = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Using Haarcascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_face_videos_using_haar(input_path: str, output_path):\n",
    "    # Create output directory if it doesn't exist\n",
    "    no_of_frames = 0\n",
    "    output_directory = os.path.dirname(output_path)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    face_cascade = cv.CascadeClassifier(HAAR_CASCADE_PATH + 'haarcascade_frontalface_alt2.xml')\n",
    "    padding = 50\n",
    "    cap = cv.VideoCapture(input_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    out = cv.VideoWriter(output_path, cv.VideoWriter_fourcc('M','J','P','G'), 30, (112, 112))\n",
    "\n",
    "    frames = []\n",
    "    while True:\n",
    "        no_of_frames = no_of_frames + 1\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        if (len(faces) == 0):\n",
    "            continue\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_region = frame[y - padding :y+h + padding, x - padding :x+w + padding]\n",
    "            resized_face = cv.resize(face_region, (112, 112))\n",
    "            out.write(resized_face)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv.destroyAllWindows()\n",
    "    print('Total frames: ', no_of_frames)\n",
    "\n",
    "# Replace the input and output paths with your actual paths\n",
    "# create_face_videos_using_haar(TRAIN_PATH + train_files[2],DATASET_PATH + '../output_face/' + train_files[2].split('haar.')[0] + '.mp4')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Using MTCNN to detect faces in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 20:33:17.238524: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-29 20:33:17.255971: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-29 20:33:17.401918: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-29 20:33:17.403461: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-29 20:33:18.002789: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "def create_face_videos_using_mtcnn(input_path, output_path):\n",
    "    detector = MTCNN()\n",
    "    # Create an object to read\n",
    "    # from camera\n",
    "\n",
    "    print(count_number_of_frames(input_path))\n",
    "\n",
    "    video = cv2.VideoCapture(input_path)\n",
    "\n",
    "    if (video.isOpened() == False):\n",
    "        print(\"Error reading video file\")\n",
    "\n",
    "    padding = 50\n",
    "\n",
    "    result = cv.VideoWriter(output_path, cv.VideoWriter_fourcc('M','J','P','G'), 30, (112, 112))\n",
    "\n",
    "    while (True):\n",
    "        ret, frame = video.read()\n",
    "        if ret == True:\n",
    "\n",
    "            location = detector.detect_faces(frame)\n",
    "            if len(location) > 0:\n",
    "                for face in location:\n",
    "                    x, y, w, h = face['box']\n",
    "                    # x2, y2 = x + width, y + height\n",
    "                    face_region = frame[y - padding :y+h + padding, x - padding :x+w + padding]\n",
    "                    resized_face = cv.resize(face_region, (112, 112))\n",
    "                    result.write(resized_face)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Break the loop\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    video.release()\n",
    "    result.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(\"The video was successfully saved\")\n",
    "\n",
    "input_path = TRAIN_PATH + train_files[2]\n",
    "output_path = DATASET_PATH + '../output_face/' + train_files[2].split('.')[0] + 'new.mp4'\n",
    "# create_face_videos_using_mtcnn(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train frames:  119974\n",
      "Total error free videos:  400\n",
      "MTCNN takes  0.6  seconds per frame\n",
      "MTCNN takes  0.03733333333333333  seconds per frame\n",
      "Total MTCNN time:  71984.4  =  (19, 59, 44) (hrs, mins, secs)\n",
      "Total Haar time:  4479.029333333333  =  (1, 14, 39) (hrs, mins, secs)\n"
     ]
    }
   ],
   "source": [
    "total_train_frames = 0\n",
    "total_error_free_videos = 0\n",
    "\n",
    "for file in train_files:\n",
    "    if file == \"metadata.json\":\n",
    "        continue\n",
    "    path = os.path.join(TRAIN_PATH, file)\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        total_train_frames += int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        total_error_free_videos += 1\n",
    "    except:\n",
    "        print(\"Error with file: \", file)\n",
    "        continue\n",
    "\n",
    "print(\"Total train frames: \", total_train_frames)\n",
    "print(\"Total error free videos: \", total_error_free_videos)\n",
    "\n",
    "\n",
    "mtcnn_time = 180 / 300\n",
    "haar_time = 11.2 / 300\n",
    "print(\"MTCNN takes \", mtcnn_time, \" seconds per frame\")\n",
    "print(\"MTCNN takes \", haar_time, \" seconds per frame\")\n",
    "\n",
    "\n",
    "total_mtcnn_time = total_train_frames * mtcnn_time\n",
    "total_haar_time = total_train_frames * haar_time\n",
    "\n",
    "def get_time_in_hrs_mins_and_secs(time):\n",
    "    hrs = int(time / 3600)\n",
    "    remaining = time - (hrs * 3600)\n",
    "    mins = int(remaining / 60)\n",
    "    remaining = remaining - (mins * 60)\n",
    "    secs = int(remaining)\n",
    "    return hrs, mins, secs\n",
    "\n",
    "print(\"Total MTCNN time: \", total_mtcnn_time, \" = \", get_time_in_hrs_mins_and_secs(total_mtcnn_time), \"(hrs, mins, secs)\")\n",
    "print(\"Total Haar time: \", total_haar_time, \" = \", get_time_in_hrs_mins_and_secs(total_haar_time), \"(hrs, mins, secs)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "\n",
    "def pre_process_dataset(method: Literal[\"haar\", \"mtcnn\"]):\n",
    "    if method == \"haar\":\n",
    "        for file_name in train_files:\n",
    "            try:\n",
    "                create_face_videos_using_haar(TRAIN_PATH + file_name, DATASET_PATH + '../output_face/' + file_name.split('.')[0] + '.mp4')\n",
    "            except:\n",
    "                print(\"Error with file: \", file_name)\n",
    "                continue\n",
    "    elif method == \"mtcnn\":\n",
    "        for file_name in train_files:\n",
    "            create_face_videos_using_mtcnn(TRAIN_PATH + file_name, DATASET_PATH + '../output_face/' + file_name.split('.')[0] + '.mp4')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method\")\n",
    "\n",
    "pre_process_dataset(\"haar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
